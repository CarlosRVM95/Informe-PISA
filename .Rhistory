ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=0.3) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=1) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=1.2) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=1.8) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=2) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=5) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=5) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.7))
ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=5) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
knitr::kable(coef(summary(lmp1)))
## Vamos a realizar una predicción con la variable Income
lmp6
knitr::kable(coef(summary(lmp6)))
summary(lmp6)
#MODELO ANOVA
modelo_1 <- lm(Overall~Income, data = PISA)
modelo_2 <- lm(Overall~poly(Income, 2), data = PISA)
modelo_3 <- lm(Overall~poly(Income, 3), data = PISA)
modelo_4 <- lm(Overall~poly(Income, 4), data = PISA)
anova(modelo_1,modelo_2,modelo_3,modelo_4)
#La función cut establece los n puntos de corte y devuelve una variable cualitativa.
set.seed(1234)
cut(runif(n=20, min=0, max= 100), breaks 5)
#La función cut establece los n puntos de corte y devuelve una variable cualitativa.
a <-set.seed(1234)
View(a)
table(cut(PISA$Income,5))
modelo_step_fun <- lm(Overall~cut(Income, 4), data = PISA)
summary(modelo_step_fun)
#INTERPOLACION DE PUNTOS DENTRO DEL RANGO DEL PREDICADOR
limites <- range(PISA$Income)
nuevos_puntos <- seq(from = limites[1], to = limites[2], by = 1)
nuevos_puntos<- data.frame(Income = nuevos_puntos)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE, level = 0.95)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones1 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE, level = 0.95)
###Calculo del intervalo de confianza superior e inferior  95%
intervalos_confianza <- data.frame(inferior = predicciones$fit - 1.96*predicciones$se.fit,
superior = predicciones$fit + 1.96*predicciones$se.fit)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones2 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE, level = 0.95)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones2 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE, level = 0.90)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones2 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE, level = 0.99)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones2 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE, level = 0.98)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones2 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE, level = cut(Income,4))
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones2 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE)
modelo_step_fun <- lm(Overall~cut(Income, 5), data = PISA)
summary(modelo_step_fun)
#INTERPOLACION DE PUNTOS DENTRO DEL RANGO DEL PREDICADOR
limites <- range(PISA$Income)
nuevos_puntos <- seq(from = limites[1], to = limites[2], by = 1)
nuevos_puntos<- data.frame(Income = nuevos_puntos)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones2 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones2 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE, level=0.95)
###Calculo del intervalo de confianza superior e inferior  95%
intervalos_confianza2 <- data.frame(inferior = predicciones$fit - 1.96*predicciones$se.fit,
superior = predicciones$fit + 1.96*predicciones$se.fit)
###Calculo del intervalo de confianza superior e inferior  95%
intervalos_confianza2 <- data.frame(inferior = predicciones2$fit - 1.96*predicciones$se.fit,
superior = predicciones2$fit + 1.96*predicciones$se.fit)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones2 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE, level=0.95)
modelo_step_fun <- lm(Overall~cut(Income, 3), data = PISA)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones2 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE, level=0.95)
modelo_step_fun <- lm(Overall~cut(Income, 2), data = PISA)
###Calculo del intervalo de confianza superior e inferior  95%
intervalos_confianza2 <- data.frame(inferior = predicciones2$fit - 1.96*predicciones$se.fit,
superior = predicciones2$fit + 1.96*predicciones$se.fit)
#PREDICCION DE LA VARIABLE RESPUESTA Y DEL ERROR ESTANDAR
###Prediccion de la variable y del error estandar
predicciones2 <- predict(modelo_step_fun, newdata = nuevos_puntos, se.fit=TRUE, level=0.95)
attach(PISA)
library(splines)
modelo_splines<- lm(Overall ~ bs(Income, knots = c(25,40,60), degree = 3),
data = PISA)
limites <- range(PISA$Income)
nuevos_puntos <- seq(from = limites[1], to = limites[2], by = 1)
nuevos_puntos<- data.frame(Income = nuevos_puntos)
Predicciones3 <- predict(modelo_splines, newdata = nuevos_puntos, se.fit = TRUE,
level = 0.95)
intervalo_conf <- data.frame(
inferior = Predicciones3$fit - 1.96*predicciones$se.fit,
superior = Predicciones3$fit + 1.96*predicciones$se.fit)
lines(x = nuevos_puntos$Income, intervalo_conf3$inferior, col = "blue",
lwd = 2, lty = 2)
intervalo_conf3 <- data.frame(
inferior = Predicciones3$fit - 1.96*predicciones$se.fit,
superior = Predicciones3$fit + 1.96*predicciones$se.fit)
plot(x = Income, y = Overall, pch = 20, col = "darkgrey")
title("Cubic Spline, knots: 25, 40, 60")
lines(x = nuevos_puntos$Income, Predicciones3$fit, col = "red", lwd = 2)
lines(x = nuevos_puntos$Income, intervalo_conf3$inferior, col = "blue",
lwd = 2, lty = 2)
lines(x = nuevos_puntos$Income, intervalo_conf3$superior, col = "blue",
lwd = 2, lty = 2)
modelo_splines <- lm(Overall ~ bs(Income, df = 6, degree = 3), data = PISA)
attr(bs(Income, df = 6, degree = 3), "knots")
modelo_smooth_splines <- smooth.spline(Overall ~ Income, cv = TRUE)
modelo_smooth_splines$df
modelo_smooth_splines$lambda
modelo_smooth_splines$spar
limites <- range(PISA$Income)
nuevos_puntos <- seq(from = limites[1], to = limites[2], by = 1)
nuevos_puntos<- data.frame(Income = nuevos_puntos)
predicciones4 <- predict(modelo_smooth_splines, newdata = nuevos_puntos)
plot(x = Overall, y = Income, pch = 20, col = "darkgrey")
title("Smooth Spline df = 4.09, lambda = 0.0085")
lines(x = predicciones4$x, predicciones4$y, col = "red", lwd = 2)
#MODELO GAM
library(splines)
modelo_gam <- lm(Overall ~ s(Issues, 4) + s(Explain, 5) + Income, data = PISA)
modelo_gam <- lm(Overall ~ ns(Issues, 4) + ns(Explain, 5) + Income, data = PISA)
modelo_gam <- lm(Overall ~ ns(Issues, 4) + lo(Explain, 5) + Income, data = PISA)
#MODELO GAM
library(splines)
modelo_gam <- gam(Overall ~ s(Issues, 4) + s(Explain, 5) + Income, data = PISA)
install.packages("gam")
library(gam)
modelo_gam <- gam(Overall ~ s(Issues,4), data = PISA)
modelo_gam <- gam(Overall ~ s(Issues,4) + s(Explain,4) + s(Evidence,4) + s(Interest,4) +
s(Support,4) + s(Income,4) + s(Health,4) + s(Edu,4) + s(HDI,4), data = PISA)
plot(modelo_gam, se =TRUE, col="blue")
summary(modelo_gam)
modelo_gam <- gam(Overall ~  s(Income,4) + s(Health,4) + s(Edu,4) + s(HDI,4), data = PISA)
plot(modelo_gam, se =TRUE, col="blue")
summary(modelo_gam)
par(mfrow=c(1,3))
plot(modelo_gam, se =TRUE, col="blue")
modelo_gam <- gam(Overall ~  s(Income,4) + s(Health,5) + s(Edu,4) + s(HDI,4), data = PISA)
plot(modelo_gam, se =TRUE, col="blue")
modelo_gam <- gam(Overall ~  s(Income,4) + s(Health,5) + s(Edu,3) + HDI, data = PISA)
plot(modelo_gam, se =TRUE, col="blue")
summary(modelo_gam)
par(mfrow=c(1,3))
plot(modelo_gam, se =TRUE, col="blue")
modelo_gam <- gam(Overall ~  s(Income,4) + s(Health,5) + s(Edu,6) + HDI, data = PISA)
plot(modelo_gam, se =TRUE, col="blue")
summary(modelo_gam)
modelo_gam <- gam(Overall ~  s(Income,4) + s(Health,5) +
Edu, data = PISA)
plot(modelo_gam, se =TRUE, col="blue")
summary(modelo_gam)
par(mfrow=c(1,3))
modelo_gam <- gam(Overall ~  s(Income,3) + s(Health,5) +
Edu, data = PISA)
plot(modelo_gam, se =TRUE, col="blue")
modelo_gam <- gam(Overall ~  s(Income,3) + s(Health,4) +
Edu, data = PISA)
plot(modelo_gam, se =TRUE, col="blue")
summary(modelo_gam)
par(mfrow=c(1,3))
plot(modelo_gam, se =TRUE, col="blue")
summary(modelo_gam)
modelo_gam <- gam(Overall ~  s(Income,5) + s(Health,6) +
Edu, data = PISA)
plot(modelo_gam, se =TRUE, col="blue")
modelo_gam <- gam(Overall ~  s(Income,3) + s(Health,3) +
s(Edu,3), data = PISA)
plot(modelo_gam, se =TRUE, col="blue")
summary(modelo_gam)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(readr)
library(gvlma)
library(MASS)
library(car)
library(ISLR)
library(splines)
colMeans(is.na(PISA))
##Edu
lmp8 <- lm(Overall ~ poly(Edu,4), data = PISA)
knitr::kable(coef(summary(lmp8)))
summary(lmp8)
##HDI
lmp9 <- lm(Overall ~ poly(HDI,4), data = PISA)
knitr::kable(coef(summary(lmp3)))
summary(lmp9)
## Vamos a realizar una predicción con la variable Income
lmp6
knitr::kable(coef(summary(lmp6)))
summary(lmp6)
###Interpolación de puntos dentro del rango del predicador
limites <- range(PISA$Income)
nuevos_puntos <- seq(from = limites[1], to = limites[2], by = 1)
nuevos_puntos<- data.frame(Income = nuevos_puntos)
###Prediccion de la variable y del error estandar
predicciones <- predict(lmp6, newdata = nuevos_puntos, se.fit=TRUE, level = 0.95)
intervalos_confianza <- data.frame(inferior = predicciones$fit - 1.96*predicciones$se.fit,
superior = predicciones$fit + 1.96*predicciones$se.fit)
ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=5) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5)) #ajusta el encabezado
colMeans(is.na(PISA))
Cols_borrar <- which(colMeans(is.na(PISA)) >= 0.13)
PISA <- PISA[, -which(colMeans(is.na(PISA)) >= 0.13)]
PISA <- as.data.frame(PISA %>% fill(colnames(PISA),.direction = "up"))
PISA
View(PISA)
PISA
Cols_borrar <- which(colMeans(is.na(PISA)) >= 0.13)
PISA <- PISA[, -which(colMeans(is.na(PISA)) >= 0.13)]
PISA <- as.data.frame(PISA %>% fill(colnames(PISA),.direction = "up"))
pisasci2006 <- read_csv("pisasci2006.csv")
PISA <- pisasci2006
View(PISA)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(readr)
library(gvlma)
library(MASS)
library(car)
library(ISLR)
library(splines)
distinct(PISA)
distinct(PISA,PISA$Issues)
distinct(PISA,PISA$Explain)
distinct(PISA,PISA$Evidence)
distinct(PISA,PISA$Interest)
distinct(PISA,PISA$Support)
distinct(PISA,PISA$Income)
distinct(PISA,PISA$Health)
distinct(PISA,PISA$Edu)
distinct(PISA,PISA$HDI)
colMeans(is.na(PISA))
Cols_borrar <- which(colMeans(is.na(PISA)) <= 0.13)
PISA <- PISA[, -which(colMeans(is.na(PISA)) <= 0.13)]
PISA <- as.data.frame(PISA %>% fill(colnames(PISA),.direction = "up"))
PISA
pisasci2006 <- read_csv("pisasci2006.csv")
PISA <- pisasci2006
##Income
lmp6 <- lm(Overall ~ poly(Income,4), data = PISA)
knitr::kable(coef(summary(lmp6)))
View(PISA)
PISA$Overall[PISA$Overall == "NA"] <- "0"
View(PISA)
PISA$Overall[PISA$Overall == "NA"] <- "0"
View(PISA)
PISA$Overall[is.na(PISA$Overall == "NA")] <- "0"
View(PISA)
PISA$Edu[is.na(PISA$Edu == "NA")] <- "0"
PISA$Overall[is.na(PISA$Overall == "NA")] <- "0"
PISA$Issues[is.na(PISA$Issues == "NA")] <- "0"
PISA$Explain[is.na(PISA$Explain == "NA")] <- "0"
PISA$Evidence[is.na(PISA$Evidence == "NA")] <- "0"
PISA$Interest[is.na(PISA$Interest == "NA")] <- "0"
PISA$Support[is.na(PISA$Support == "NA")] <- "0"
PISA$Income[is.na(PISA$Income == "NA")] <- "0"
PISA$Health[is.na(PISA$Health == "NA")] <- "0"
PISA$Edu[is.na(PISA$Edu == "NA")] <- "0"
PISA$HDI[is.na(PISA$HDI == "NA")] <- "0"
View(PISA)
modelo_1 <- lm(Overall~Income, data = PISA)
modelo_2 <- lm(Overall~poly(Income, 2), data = PISA)
modelo_3 <- lm(Overall~poly(Income, 3), data = PISA)
modelo_4 <- lm(Overall~poly(Income, 4), data = PISA)
##Income
lmp6 <- lm(Overall ~ poly(Income,4), data = PISA)
knitr::kable(coef(summary(lmp6)))
summary(lmp6)
###Interpolación de puntos dentro del rango del predicador
limites <- range(PISA$Income)
nuevos_puntos <- seq(from = limites[1], to = limites[2], by = 1)
nuevos_puntos<- data.frame(Income = nuevos_puntos)
###Prediccion de la variable y del error estandar
predicciones <- predict(lmp6, newdata = nuevos_puntos, se.fit=TRUE, level = 0.95)
###Calculo del intervalo de confianza superior e inferior  95%
intervalos_confianza <- data.frame(inferior = predicciones$fit - 1.96*predicciones$se.fit,
superior = predicciones$fit + 1.96*predicciones$se.fit)
ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=5) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5)) #ajusta el encabezado
ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=5) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5)) #ajusta el encabezado
###Calculo del intervalo de confianza superior e inferior  95%
intervalos_confianza <- data.frame(inferior = predicciones$fit - 1.96*predicciones$se.fit,
superior = predicciones$fit + 1.96*predicciones$se.fit)
ggplot(data=PISA, aes(x=Income, y= Overall)) +
geom_point(color = "grey30", alpha=5) +
geom_smooth(method = lm, formula = y ~ poly(x,4), color = "red") +
labs(title = "Polinomio 4 PISA~Income") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5)) #ajusta el encabezado
modelo_gam <- gam (Overall ~ Issues + Explain + Evidence + Interest + Support + Income + Health + Edu
+ HDI, data = PISA)
pisasci2006 <- read_csv("pisasci2006.csv")
PISA <- pisasci2006
modelo_gam <- gam (Overall ~ Issues + Explain + Evidence + Interest + Support + Income + Health + Edu
+ HDI, data = PISA)
plot(modelo_gam, se = TRUE, col = "blue")
summary(modelo_gam)
qplot(modelo_gam, se = TRUE, col = "blue")
plot(modelo_gam, se = TRUE, col = "blue")
plot(modelo_gam, se = TRUE, col = "red")
modelo_gam <- gam (Overall ~ s(Issues,4) + Explain + Evidence + Interest + Support + Income + Health + Edu
+ HDI, data = PISA)
plot(modelo_gam, se = TRUE, col = "red")
modelo_gam <- gam (Overall ~ s(Issues,4) + Explain + Evidence + Interest + Support + Income + s(Health,4) + Edu
+ HDI, data = PISA)
plot(modelo_gam, se = TRUE, col = "red")
summary(modelo_gam) # Estos p-values se corresponden con el contraste de hipótesis de que la relación entre predictor y variable respuesta es lineal, frente a la alternativa de que no lo es.
modelo_gam <- gam (Overall ~ Issues + Explain + Evidence + Interest + Support + Income + Health + Edu
+ HDI, data = PISA)
summary(modelo_gam) # Estos p-values se corresponden con el contraste de hipótesis de que la relación entre predictor y variable respuesta es lineal, frente a la alternativa de que no lo es.
modelo_gam2 <- gam (Overall ~ Issues + Explain + Evidence + s(Interest,4) + s(Support,4) + s(Income,4)
+ s(Health,4) + s(Edu,4)+ s(HDI,4), data = PISA)
summary(modelo_gam2)
modelo_gam2 <- gam (Overall ~ Issues + Explain + Evidence + s(Interest,5) + s(Support,6) + s(Income,6)
+ s(Health,6) + s(Edu,6)+ s(HDI,4), data = PISA)
summary(modelo_gam2)
modelo_gam2 <- gam (Overall ~ Issues + Explain + Evidence + s(Interest,5) + s(Support,7) + s(Income,7)
+ s(Health,7) + s(Edu,7)+ s(HDI,4), data = PISA)
summary(modelo_gam2)
modelo_gam2 <- gam (Overall ~ Issues + Explain + Evidence + s(Interest,5) + s(Support,10) + s(Income,9)
+ s(Health,9) + s(Edu,9)+ s(HDI,4), data = PISA)
summary(modelo_gam2)
modelo_gam2 <- gam (Overall ~ Issues + Explain + Evidence + s(Interest,5) + s(Support,8) + s(Income,8)
+ s(Health,8) + s(Edu,8)+ s(HDI,4), data = PISA)
summary(modelo_gam2)
crPlot(modelo_gam)
drop1(modelo_gam, parallel = "multicore", ncpus= 4)
termplot(modelo_gam, pages = 1, ask = FALSE, rug = TRUE)
list(mean = mean, median = median)
tibble::lst(mean, median)
list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))
PISA
PISA$Overall[is.na(PISA$Overall)] <- round(mean(PISA$Overall, na.rm = TRUE)
View(PISA)
View(PISA)
PISA$Overall[is.na(PISA$Overall)] <- round(mean(PISA$Overall, na.rm = TRUE)
View(PISA)
View(PISA)
PISA$Overall[is.na(PISA$Overall)] <- round(mean(PISA$Overall, na.rm = TRUE)
View(PISA)
PISA$Overall[is.na(PISA$Overall)] <- round(mean(PISA$Overall, na.rm = TRUE)
PISA$Overall[is.na(PISA$Overall)] <- round(mean(PISA$Overall, na.rm = TRUE))
PISA$Overall[is.na(PISA$Overall)] <- round(mean(PISA$Overall, na.rm = TRUE))
View(PISA)
PISA$Overall[is.na(PISA$Overall)] <- round(mean(PISA$Overall, na.rm = TRUE))
PISA$Issues[is.na(PISA$Issues)] <- round(mean(PISA$Issues, na.rm = TRUE))
PISA$Explain[is.na(PISA$Explain)] <- round(mean(PISA$Explain, na.rm = TRUE))
PISA$Evidence[is.na(PISA$Evidence)] <- round(mean(PISA$Evidence, na.rm = TRUE))
PISA$Interest[is.na(PISA$Interest)] <- round(mean(PISA$Interest, na.rm = TRUE))
PISA$Support[is.na(PISA$Support)] <- round(mean(PISA$Support, na.rm = TRUE))
PISA$Income[is.na(PISA$Income)] <- round(mean(PISA$Income, na.rm = TRUE))
PISA$Health[is.na(PISA$Health)] <- round(mean(PISA$Health, na.rm = TRUE))
PISA$Edu[is.na(PISA$Edu)] <- round(mean(PISA$Edu, na.rm = TRUE))
PISA$HDI[is.na(PISA$HDI)] <- round(mean(PISA$HDI, na.rm = TRUE))
View(PISA)
skim(PISA)
ggplot(PISA, aes(Issues,Overall)) +
geom_lines() +
xlab("Issues") +
ylab("Overall") +
theme_base() +
theme(plot.background = element_rect(color = NA))
#Gráficos lineales
ggplot(PISA, aes(Issues,Overall)) +
geom_point() +
xlab("Issues") +
ylab("Overall") +
theme_base() +
theme(plot.background = element_rect(color = NA))
ggplot(PISA, aes(Issues,Overall)) +
geom_point() +
xlab("Issues") +
ylab("Overall") +
#Gráficos lineales
ggplot(PISA, aes(Issues,Overall)) +
geom_point() +
xlab("Issues") +
ylab("Overall") +
# Cremo modelos polinomicos con todas las variables
## Issues
lmp1 <- lm(Overall ~ poly(Issues,4), data = PISA)
#Gráficos lineales
ggplot(PISA, aes(x = Issues, y = Overall)) +
geom_point() +
xlab("Issues") +
ylab("Overall") +
# Cremo modelos polinomicos con todas las variables
## Issues
lmp1 <- lm(Overall ~ poly(Issues,4), data = PISA)
p <- ggplot(PISA, aes(x = Issues, y = Overall)) +
geom_point() +
xlab("Issues") +
ylab("Overall") +
#Gráficos lineales
p <- ggplot(PISA, aes(x = Issues, y = Overall)) +
geom_point() +
xlab("Issues") +
ylab("Overall") +
p
p <- ggplot(PISA, aes(x = Issues, y = Overall)) +
geom_point() +
xlab("Issues") +
ylab("Overall") +
p <- ggplot(PISA, aes(x = Issues, y = Overall)) +
geom_point() +
xlab("Issues") +
ylab("Overall") +
p
#Gráficos lineales
plot(PISA$Issues, PISA$Overall)
#Gráficos lineales
plot(PISA$Overall, PISA$Issues)
plot(PISA$Overall, PISA$Explain)
plot(PISA$Overall, PISA$Evidence)
plot(PISA$Overall, PISA$Support)
plot(PISA$Overall, PISA$Income)
plot(PISA$Overall, PISA$Edu)
plot(PISA$Overall, PISA$HDI)
cor(PISA)
cor(PISA)
library(PerformanceAnalytics)
CorPISA <- data.frame(Overall, Issues,Explain,Evidence,Interest,Support,Income,Health,Edu,HDI)
chart.Correlation(CorPISA)
modelo_gam <- gam (Overall ~  s(Interest) + s(Support) + s(Income) + s(Health) + s(Edu)
+ s(HDI), data = PISA)
smooth.spline(x = PISA$interest, y = PISA$overall, cv = TRUE)
smooth.spline(x = PISA$Interest, y = PISA$Overall, cv = TRUE)
smooth.spline(PISA$Income, PISA$Overall, cv = TRUE)
smooth.spline(x = PISA$Support, y = PISA$Overall, cv = TRUE)
smooth.spline(x = PISA$Health, y = PISA$Overall, cv = TRUE)
smooth.spline(x = PISA$Edu, y = PISA$Overall, cv = TRUE)
smooth.spline(x = PISA$HDI, y = PISA$Overall, cv = TRUE)
modelo_gam <- gam (Overall ~  s(Interest,5) + s(Support,10) + s(Income,2) + s(Health,2) + s(Edu,6)
+ s(HDI,7), data = PISA)
plot(modelo_gam, se = TRUE, col = "red")
summary(modelo_gam)
modelo_gam2 <- gam (Overall ~  s(Interest,5) + s(Support,10) + s(Income,2) + Health + Edu
+ HDI, data = PISA)
summary(modelo_gam2)
modelo_gam3 <- gam (Overall ~  s(Interest,5) + s(Support,10) + s(Income,2) + lo(Health,span = 0.7) + lo(Edu, span = 0.7)
+ lo(HDI, span = 0.7), data = PISA)
plot(modelo_gam3, se = TRUE, col = "red")
summary(modelo_gam3)
anova(modelo_gam,modelo_gam2,modelo_gam3)
anova(modelo_gam,modelo_gam2,modelo_gam3, test = F)
anova(modelo_gam,modelo_gam2,modelo_gam3, test = 'F')
